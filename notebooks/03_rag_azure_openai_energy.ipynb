{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba21563",
   "metadata": {},
   "source": [
    "## 1. Load Energy Document Corpus\n",
    "Use scraped or sample energy technical documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465ad79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow version: 15.0.0\n",
      "Python executable: /Users/justin/miniconda3_Jun2023/envs/lora-llm/bin/python\n"
     ]
    }
   ],
   "source": [
    "import pyarrow\n",
    "import sys\n",
    "print(\"pyarrow version:\", pyarrow.__version__)\n",
    "print(\"Python executable:\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5315b364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oil production forecasting is the prediction of future oil output from wells using historical and engineering data.',\n",
       " 'Reservoir pressure is a key factor affecting oil production rates.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/energy_text.txt') as f:\n",
    "    docs = [line.strip() for line in f if line.strip()]\n",
    "docs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece5b04",
   "metadata": {},
   "source": [
    "## 2. Azure OpenAI Embeddings\n",
    "Use text-embedding-ada-002 for vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34aafc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/miniconda3_Jun2023/envs/lora-llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from typing import List\n",
    "\n",
    "# Try to import sentence-transformers for local fallback\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    _has_hf = True\n",
    "except ImportError:\n",
    "    _has_hf = False\n",
    "\n",
    "# Check for Azure OpenAI credentials\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "AZURE_OPENAI_KEY = os.getenv('AZURE_OPENAI_KEY')\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Returns embedding for text using Azure OpenAI if credentials are set, otherwise uses Hugging Face sentence-transformers.\n",
    "    \"\"\"\n",
    "    if AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_KEY:\n",
    "        openai.api_type = 'azure'\n",
    "        openai.api_base = AZURE_OPENAI_ENDPOINT\n",
    "        openai.api_key = AZURE_OPENAI_KEY\n",
    "        resp = openai.embeddings.create(input=[text], model='text-embedding-ada-002')\n",
    "        return resp.data[0].embedding\n",
    "    elif _has_hf:\n",
    "        # Use Hugging Face all-MiniLM-L6-v2 as fallback\n",
    "        if not hasattr(get_embedding, '_model'):\n",
    "            get_embedding._model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        return get_embedding._model.encode(text).tolist()\n",
    "    else:\n",
    "        raise RuntimeError('No embedding provider available. Set Azure OpenAI credentials or install sentence-transformers.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead64f47",
   "metadata": {},
   "source": [
    "> **Tip:** This notebook will use Azure OpenAI for embeddings if credentials are set, otherwise it will fall back to Hugging Face sentence-transformers (all-MiniLM-L6-v2). To enable Azure, set `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_KEY` in your environment. To use the local fallback, ensure `sentence-transformers` is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49956955",
   "metadata": {},
   "source": [
    "## 3. Store Embeddings in ChromaDB\n",
    "Vector store for fast retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f0d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection('energy_docs')\n",
    "for i, doc in enumerate(docs):\n",
    "    emb = get_embedding(doc)\n",
    "    collection.add(documents=[doc], embeddings=[emb], ids=[str(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ffa78",
   "metadata": {},
   "source": [
    "## 4. RAG Pipeline: Retrieval + Generation\n",
    "Retrieve relevant docs and generate answer with Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17eb62ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reservoir pressure affects oil production by pushing the oil from underground reservoirs to the surface. When this natural pressure declines, the rate of oil production can decrease. This is why artificial lift methods or enhanced oil recovery techniques may be implemented to increase the pressure and enhance oil production.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rag_query(query):\n",
    "    q_emb = get_embedding(query)\n",
    "    results = collection.query(query_embeddings=[q_emb], n_results=3)\n",
    "    context = '\\n'.join([d for d in results['documents'][0]])\n",
    "    prompt = f'Context: {context}\\n\\nQuestion: {query}\\nAnswer:'\n",
    "    # For openai>=1.0.0\n",
    "    response = openai.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "rag_query('How does reservoir pressure affect oil production?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d313269",
   "metadata": {},
   "source": [
    "## 5. Cost Tracking\n",
    "Log token usage and estimate cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6d3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: log token usage\n",
    "def log_cost(response):\n",
    "    usage = response['usage']\n",
    "    tokens = usage['total_tokens']\n",
    "    cost = tokens * 0.00002  # Example cost per token\n",
    "    print(f'Tokens: {tokens}, Estimated Cost: ${cost:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8969de",
   "metadata": {},
   "source": [
    "## 6. Prompt Engineering\n",
    "Try few-shot and chain-of-thought prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0799deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = '''\n",
    "Context: Oil production depends on reservoir pressure.\n",
    "\n",
    "        Question: What is reservoir pressure?\n",
    "        Answer: Reservoir pressure is the pressure of fluids within a reservoir.\n",
    "        \n",
    "        Question: How does it affect oil production?\n",
    "        Answer: Higher reservoir pressure generally increases oil production.\n",
    "        \n",
    "        Question: What happens when pressure drops?\n",
    "        Answer: Oil production typically declines.\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae545a2a",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n",
    "Evaluate retrieval accuracy and answer quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
